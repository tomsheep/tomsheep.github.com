---
layout: post
category: 儒林外史
title: 祛魅（5）
date: 2012-12-16 22:36:21 +08:00
tagline:
tags: [统计学习, ML]
---


### Notes on《统计学习方法》(李航)-1：

1. 统计学习的方法是基于数据构建统计模型从而对数据进行预测和分析。统计学习的三要素：模型、策略、算法。

    * 在监督学习（训练数据既有输入也有输出）中，模型就是所要学习的条件概率或决策函数。

    * 策略：确定了假设空间后，就需要考虑按照什么样的准则学习或选择最优模型。监督学习的两个基本策略是经验风险最小化和结构风险最小化。风险函数是损失函数的期望，学习的目标就是选择期望风险（泛化误差）最小的模型。期望风险`R_exp(f)`是模型关于联合分布的期望损失，经验风险`R_emp(f)`是模型关于训练样本集的平均损失。当样本容量趋于无穷时，`R_emp(f)`趋于`R_exp(f)`. 通常用经验风险估计期望风险。 当样本容量过小时，经验风险最小化容易出现“过拟合”（模型过于复杂，对已知数据预测的好，对未知数据预测过差）；结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer) J(f)，表示了对复杂模型的惩罚。正则化符合奥卡姆剃刀原理：在所有可能选择的模型中，能够很好的解释已知数据并且十分简单才是最好的模型。一句话就是be simple.  

    * 算法指学习模型的具体计算方法。这时学习问题归结为最优化问题。

2. 交叉验证的基本想法是重复地使用数据，把给定的数据进行切分，将切分数据集组合为训练集与测试集，反复进行训练、测试以及模型选择。常用方法有简单交叉验证（将已知数据随机氛围训练集和测试集）、S折交叉验证（将数据切分为S个大小相同的子集，S-1个用于训练，余下的作为测试集，对S种选择重复进行）、留一交叉验证（S折里S=N的特殊情况）

3. 监督学习方法可以分为生成方法和判别方法。生成方法由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型（如朴素贝叶斯法和隐马尔可夫模型）；判别方法由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测的模型，关心的是给定输入X，应该预测什么样的输出Y。

    * 生成方法可以还原出联合概率分布P(X,Y)，收敛速度更快

    * 判别方法直接面对预测，往往学习的准确率更高。

4. 输入变量X与输出变量Y均为连续变量的预测问题成为回归问题（学习过程等价于函数拟合）；Y为有限个离散变量的称为分类问题；X，Y均为变量序列的称为标注问题。

