---
layout: post
category : 儒林外史
title: 祛魅（8）
date: 2013-01-15 23:52:31 +08:00
tagline:
tags: [机器学习, ML, Andrew Ng, 李航, 概率, 统计]
---


小结一下近期的ML学习：

一开始进展非常缓慢，迷失在各种希腊字母和公式里，抓不到核心，也没有贴笔记，因为笔记只有在看懂了的前提下才会起加强理解的作用。后来耐下心查阅遇到的生僻概念，稍微补习了些概率知识，逐渐就没有那么唬人了。

分析一下这一个多月学习遇到的困难，原因大概有：

1. 数学尤其是概率论基础比较差，冷启动比较吃力。大学里的《概率论》与《人工智能》课能翘的都翘了……（但这两门课哥都拿了A，哥“混”的能力不是盖的）

2. 李航的书不适合0基础学员。中国人写书有通病，就是“彪悍不解释”，懂的人怎么看怎么懂，不懂的人怎么看还是不懂。第一遍看到一半就接近天书了，看10分钟书得查2小时wikipedia。后来和Andew Ng的视频以及Tom Mitchell的《机器学习》结合着看，效果就好多了。

3. 学习方法不好，一上来就抓算法，容易浮在表面，看不到模型背后的道理。Andrew Ng教程里有段话，我觉得说的太好，大意是“懂机器学习就像木匠会用工具一样，工具大家都会用，一个好木匠和一般木匠的差别在于知道如何选择工具，并且如何把它运用的更好”。

这一个多月的笔记暂时不整理了，我觉得还不到时候，等有了所谓sense的时候再总结会更合适。简单列一下各主题的资料：

1. 生成模型vs.判别模型

    * [科学网—判别模型 和 生成模型 - 龚书的博文](http://blog.sciencenet.cn/home.php?mod=space&amp;uid=248173&amp;do=blog&amp;id=227964)
    * [判别模型、生成模型与朴素贝叶斯方法 - JerryLead - 博客园](http://www.cnblogs.com/jerrylead/archive/2011/03/05/1971903.html)
    * [什么是判别模型(Discriminative Model)和生成模型(Generative Model) | GooSeeker](http://www.gooseeker.com/cn/node/knowledgebase/discriminative_generative_model)
    * [最大似然估计(Maximum likelihood estimation) - 可乐LL - 博客园](http://www.cnblogs.com/liliu/archive/2010/11/22/1883702.html)

2. 逻辑回归

    * [Coursera公开课笔记: 斯坦福大学机器学习第六课‘逻辑回归(Logistic Regression)](http://52opencourse.com/125/coursera%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%AC%E5%85%AD%E8%AF%BE-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression)
    * [sigmoid函数详解](http://blog.163.com/liyanhua_08/blog/static/1172002772009927111741738/)
    * [Stanford机器学习---第三讲. 逻辑回归和过拟合问题的解决](http://blog.csdn.net/abcjennifer/article/details/7716281)

3. 人工神经网络：

    * [人工神经网络（ANN）](http://blog.csdn.net/wasd6081058/article/details/7909733) 
    * [线性学习器-----最小二乘法 Rosenblatt感知机 delta法则](http://blog.csdn.net/wasd6081058/article/details/7886697)

4. 支持向量机

    * [SVM入门（七）为何需要核函数](http://blog.csdn.net/cc198877/article/details/8049203) 
    * [SVM入门（五）线性分类器的求解——问题的描述Part2](http://blog.csdn.net/cc198877/article/details/8048668)
    * [VC dimension - Wikipedia, the free encyclopedia.](http://en.wikipedia.org/wiki/VC_dimension) 
    * [结构风险最小和VC维理论的解释 - 李海波](http://blog.csdn.net/marising/article/details/5888531)
    * [结构风险最小化_百度百科](http://baike.baidu.com/view/5765845.htm)
    * [支持向量机通俗导论（理解SVM的三层境界）](http://blog.csdn.net/v_july_v/article/details/7624837)

5. Boosting

    * [adaboost学习（一）](http://blog.csdn.net/szv123_rier/article/details/7963541)
    * [机器学习中的数学(3)-模型组合(Model Combining)之Boosting与Gradient Boosting](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/02/machine-learning-boosting-and-gradient-boosting.html)

6. 条件随机场

    * [随机场-Random Field](http://www.zhizhihu.com/html/y2010/2312.html)
    * [条件随机场_百度文库](http://wenku.baidu.com/view/f32a35d2240c844769eaee55.html)

