---
layout: post
category : 儒林外史
title: 屌丝的自我修养（88）
date: 2012-08-28 22:36:12 +08:00
tagline:
tags: [Professional, 陶伟, Heaps定律, 搜索, 词典压缩, Zipf定律, 环保, 北京]
---


1. 在面对一坨屎的时候，我通常都倾向于选择不吃屎，而不是换个优雅的姿势去吃。——这大概就是我还不够“professional”的原因吧。

2. 把printscreen放在backspace上面是个非常糟糕的设计，每天我要误截好多张屏——你说这键盘要是落在冠西哥手上还了得？

3. 北京环保搞不好，大约和鬼节太多有关。——回家路上看着一路冥纸烧过的余烬，心想咱能不能走支付宝啊？

4. 早上被陶指导逝世的消息惊了一下。这样的故事每天都在发生，多数情况下只是一条无关痛痒的新闻；而突然发生在一个你还算熟悉的人身上，就会带来很大的冲击，产生一种怜惜、也许还有自怜的感觉，觉得上帝开的这门课，指不定什么时候就挂到了你的头上。况且北京坑这么多……我就说我为什么这么不爱看《一站到底》。

5. 词项数目估计的Heaps定律：词项数目可以估计成文档集大小的一个函数 `M = kT^b` 其中M是词项数目，T是文档集合中词条的个数，参数k和b的典型取值为`30 <= k <= 100`, b约为0.5

6. 对词项分布建模的Zipf定律：如果t1是文档集中出现最多词项，t2是第二多词项，以此类推，那么，排名第i多的词项的文档集频率cfi和1/i 成正比。
也就是说，cf2约是cf1的1/2，cf3约是cf1的1/3……

7. 词典压缩：

    * 主要目的是将（大部分）词典放入内存

    * 采用定长存储词项一般会比较浪费，一种解决方法是将所有词项存成一个长字符串，并给每个词项加一个定位指针。而且可以进一步压缩，将长字符串中的词项进行分组变成大小为k的块，然后对每个块只保留第一个词项的指针。这种做法需要在压缩率和查找速度间进行tradeoff

    * 可以利用front coding技术利用词项之间的冗余信息。识别公共前缀，后续词项中便可以使用一个特殊的字符来代表这段前缀。

    * 如果不得不吧词典划分成不同页存在磁盘上，则可以采用B树对每页的第一个词项进行索引。

8. 倒排记录表的压缩：

    * 高频词出现的文档ID序列号之间间隔不大。利用这一点，可以使用比序列号最大长度更少的bit数来存储间隔。

    * 因为间隔可大可小，所以一般需要可变字节来编码（比如用一个字节的7位表示payload，剩下一位留做延续位）

    * 一个和最优编码长度差距在常数倍之内的方法是γ编码。γ编码将间距G表示为长度和偏移两个部分进行变长编码。G的偏移实际上是G的二进制编码去掉前端的1, 长度是指偏移的长度，用一元编码表示。这样，偏移部分长度是log2(G), 长度上限是log2(G) + 1，则全编码上限是2 * log2(G) + 1。

    * γ编码较为通用，而且是prefix-free code，一个γ编码不会是另一个的前缀，不需要对γ编码进行切分；γ编码也是parameter free的，其他很多高效的编码方式需要对模型的参数进行拟合使之适应于索引中间距的分布情况，这样会加大压缩和解压缩的复杂性。
